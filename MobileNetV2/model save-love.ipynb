{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "niubi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htR9aEa1OX2H",
        "outputId": "53d60ea7-460b-47b6-bb6a-90532da88320"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torch.optim as optim\n",
        "import time\n",
        "import os\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomGrayscale(),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "transform1 = transforms.Compose(\n",
        "    [\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform1)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-SMP0TFSirc",
        "outputId": "245fe29f-7482-4572-87a5-fdd0c56de571"
      },
      "source": [
        "transforms.RandomHorizontalFlip(),\n",
        "transforms.RandomGrayscale(),"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(RandomGrayscale(p=0.1),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHR05-ZWSjYt",
        "outputId": "70f0646b-a68a-4196-88cd-6cc6be43bd7c"
      },
      "source": [
        "transforms.ToTensor(),\n",
        "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv72dP-DS5W1",
        "outputId": "35646183-33f6-444e-ace2-aa2e4ae382ff"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzS2Pa-_Orjz"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    '''expand + depthwise + pointwise'''\n",
        "    def __init__(self, in_planes, out_planes, expansion, stride):\n",
        "        super(Block, self).__init__()\n",
        "        self.stride = stride\n",
        "\n",
        "        planes = expansion * in_planes\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, \n",
        "                               stride=1, padding=0, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, \n",
        "                               stride=stride, padding=1, groups=planes, \n",
        "                               bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, \n",
        "                               stride=1, padding=0, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride == 1 and in_planes != out_planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, \n",
        "                          stride=1, padding=0, bias=False),\n",
        "                nn.BatchNorm2d(out_planes),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out = out + self.shortcut(x) if self.stride==1 else out\n",
        "        return out\n",
        "\n",
        "\n",
        "class MobileNetV2(nn.Module):\n",
        "    # (expansion, out_planes, num_blocks, stride)\n",
        "    cfg = [(1,  16, 1, 1),\n",
        "           (6,  24, 2, 1),  # NOTE: change stride 2 -> 1 for CIFAR10\n",
        "           (6,  32, 3, 2),\n",
        "           (6,  64, 4, 2),\n",
        "           (6,  96, 3, 1),\n",
        "           (6, 160, 3, 2),\n",
        "           (6, 320, 1, 1)]\n",
        "\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(MobileNetV2, self).__init__()\n",
        "        # NOTE: change conv1 stride 2 -> 1 for CIFAR10\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, \n",
        "                               padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(32)\n",
        "        self.layers = self._make_layers(in_planes=32)\n",
        "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, \n",
        "                               padding=0, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(1280)\n",
        "        self.linear = nn.Linear(1280, num_classes)\n",
        "\n",
        "    def _make_layers(self, in_planes):\n",
        "        layers = []\n",
        "        for expansion, out_planes, num_blocks, stride in self.cfg:\n",
        "            strides = [stride] + [1]*(num_blocks-1)\n",
        "            for stride in strides:\n",
        "                layers.append(\n",
        "                    Block(in_planes, out_planes, expansion, stride))\n",
        "                in_planes = out_planes\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layers(out)\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        # NOTE: change pooling kernel_size 7 -> 4 for CIFAR10\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "    def train_sgd(self,device):\n",
        "        optimizer = optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        path = 'weights.tar'\n",
        "        initepoch = 0\n",
        "\n",
        "        if os.path.exists(path) is not True:\n",
        "            loss = nn.CrossEntropyLoss()\n",
        "            # optimizer = optim.SGD(self.parameters(),lr=0.01)\n",
        "\n",
        "        else:\n",
        "            checkpoint = torch.load(path)\n",
        "            self.load_state_dict(checkpoint['model_state_dict'])\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "            initepoch = checkpoint['epoch']\n",
        "            loss = checkpoint['loss']\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        for epoch in range(initepoch,100):  # loop over the dataset multiple times\n",
        "            timestart = time.time()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            total = 0\n",
        "            correct = 0\n",
        "            for i, data in enumerate(trainloader, 0):\n",
        "                # get the inputs\n",
        "                inputs, labels = data\n",
        "                inputs, labels = inputs.to(device),labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward + backward + optimize\n",
        "                outputs = self(inputs)\n",
        "                l = loss(outputs, labels)\n",
        "                l.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # print statistics\n",
        "                running_loss += l.item()\n",
        "                # print(\"i \",i)\n",
        "                if i % 500 == 499:  # print every 500 mini-batches\n",
        "                    print('[%d, %5d] loss: %.4f' %\n",
        "                          (epoch, i, running_loss / 500))\n",
        "                    running_loss = 0.0\n",
        "                    _, predicted = torch.max(outputs.data, 1)\n",
        "                    total += labels.size(0)\n",
        "                    correct += (predicted == labels).sum().item()\n",
        "                    print('Accuracy of the network on the %d tran images: %.3f %%' % (total,\n",
        "                            100.0 * correct / total))\n",
        "                    total = 0\n",
        "                    correct = 0\n",
        "                    torch.save({'epoch':epoch,\n",
        "                                'model_state_dict':net.state_dict(),\n",
        "                                'optimizer_state_dict':optimizer.state_dict(),\n",
        "                                'loss':loss\n",
        "                                },path)\n",
        "\n",
        "            print('epoch %d cost %3f sec' %(epoch,time.time()-timestart))\n",
        "\n",
        "        print('Finished Training')\n",
        "        torch.save(model, path)\n",
        "      \n",
        "\n",
        "    def test(self,device):\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                images, labels = data\n",
        "                images, labels = images.to(device), labels.to(device)\n",
        "                outputs = self(images)\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        print('Accuracy of the network on the 10000 test images: %.3f %%' % (\n",
        "                100.0 * correct / total))\n",
        "inputs, labels = data\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "inputs, labels = inputs.to(device),labels.to(device)\n",
        "model = torch.load(PATH)\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVsp6N_XPRBY",
        "outputId": "65fb7f86-1026-4e86-e59b-c03f013a8bb0"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "net = MobileNetV2()\n",
        "net = net.to(device)\n",
        "net.train_sgd(device)\n",
        "net.test(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0,   499] loss: 1.7205\n",
            "Accuracy of the network on the 100 tran images: 45.000 %\n",
            "epoch 0 cost 2534.015327 sec\n",
            "[1,   499] loss: 1.3501\n",
            "Accuracy of the network on the 100 tran images: 42.000 %\n",
            "epoch 1 cost 2628.035059 sec\n",
            "[2,   499] loss: 1.1441\n",
            "Accuracy of the network on the 100 tran images: 59.000 %\n",
            "epoch 2 cost 2666.212991 sec\n",
            "[3,   499] loss: 1.0019\n",
            "Accuracy of the network on the 100 tran images: 65.000 %\n",
            "epoch 3 cost 2645.985409 sec\n",
            "[4,   499] loss: 0.8890\n",
            "Accuracy of the network on the 100 tran images: 75.000 %\n",
            "epoch 4 cost 2699.672699 sec\n",
            "[5,   499] loss: 0.8024\n",
            "Accuracy of the network on the 100 tran images: 75.000 %\n",
            "epoch 5 cost 2704.552212 sec\n",
            "[6,   499] loss: 0.7233\n",
            "Accuracy of the network on the 100 tran images: 75.000 %\n",
            "epoch 6 cost 2775.380861 sec\n",
            "[7,   499] loss: 0.6488\n",
            "Accuracy of the network on the 100 tran images: 82.000 %\n",
            "epoch 7 cost 2834.292503 sec\n",
            "[8,   499] loss: 0.5934\n",
            "Accuracy of the network on the 100 tran images: 83.000 %\n",
            "epoch 8 cost 2804.287303 sec\n",
            "[9,   499] loss: 0.5270\n",
            "Accuracy of the network on the 100 tran images: 82.000 %\n",
            "epoch 9 cost 2800.018692 sec\n",
            "[10,   499] loss: 0.4780\n",
            "Accuracy of the network on the 100 tran images: 83.000 %\n",
            "epoch 10 cost 2823.692612 sec\n",
            "[11,   499] loss: 0.4253\n",
            "Accuracy of the network on the 100 tran images: 89.000 %\n",
            "epoch 11 cost 2809.690924 sec\n",
            "[12,   499] loss: 0.3863\n",
            "Accuracy of the network on the 100 tran images: 89.000 %\n",
            "epoch 12 cost 2835.718858 sec\n",
            "[13,   499] loss: 0.3484\n",
            "Accuracy of the network on the 100 tran images: 87.000 %\n",
            "epoch 13 cost 2781.345368 sec\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-dd0bf6eff861>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMobileNetV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_sgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-6a8a0e2822d8>\u001b[0m in \u001b[0;36mtrain_sgd\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    116\u001b[0m                 \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m                 \u001b[0ml\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m                 \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grTdc7PfTPsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}