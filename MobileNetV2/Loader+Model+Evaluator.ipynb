{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "niubi.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "htR9aEa1OX2H",
        "outputId": "53d60ea7-460b-47b6-bb6a-90532da88320"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torchvision\r\n",
        "import torchvision.transforms as transforms\r\n",
        "import torch.optim as optim\r\n",
        "import time\r\n",
        "import os\r\n",
        "\r\n",
        "transform = transforms.Compose(\r\n",
        "    [\r\n",
        "     transforms.RandomHorizontalFlip(),\r\n",
        "     transforms.RandomGrayscale(),\r\n",
        "     transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "transform1 = transforms.Compose(\r\n",
        "    [\r\n",
        "     transforms.ToTensor(),\r\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\r\n",
        "\r\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\r\n",
        "                                          shuffle=True, num_workers=2)\r\n",
        "\r\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\r\n",
        "                                       download=True, transform=transform1)\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=50,\r\n",
        "                                         shuffle=False, num_workers=2)\r\n",
        "\r\n",
        "classes = ('plane', 'car', 'bird', 'cat',\r\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-SMP0TFSirc",
        "outputId": "245fe29f-7482-4572-87a5-fdd0c56de571"
      },
      "source": [
        "transforms.RandomHorizontalFlip(),\r\n",
        "transforms.RandomGrayscale(),"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(RandomGrayscale(p=0.1),)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gHR05-ZWSjYt",
        "outputId": "70f0646b-a68a-4196-88cd-6cc6be43bd7c"
      },
      "source": [
        "transforms.ToTensor(),\r\n",
        "transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qv72dP-DS5W1",
        "outputId": "35646183-33f6-444e-ace2-aa2e4ae382ff"
      },
      "source": [
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\r\n",
        "                                        download=True, transform=transform)\r\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,\r\n",
        "                                          shuffle=True, num_workers=2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzS2Pa-_Orjz"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "\r\n",
        "\r\n",
        "class Block(nn.Module):\r\n",
        "    '''expand + depthwise + pointwise'''\r\n",
        "    def __init__(self, in_planes, out_planes, expansion, stride):\r\n",
        "        super(Block, self).__init__()\r\n",
        "        self.stride = stride\r\n",
        "\r\n",
        "        planes = expansion * in_planes\r\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, \r\n",
        "                               stride=1, padding=0, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\r\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, \r\n",
        "                               stride=stride, padding=1, groups=planes, \r\n",
        "                               bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\r\n",
        "        self.conv3 = nn.Conv2d(planes, out_planes, kernel_size=1, \r\n",
        "                               stride=1, padding=0, bias=False)\r\n",
        "        self.bn3 = nn.BatchNorm2d(out_planes)\r\n",
        "\r\n",
        "        self.shortcut = nn.Sequential()\r\n",
        "        if stride == 1 and in_planes != out_planes:\r\n",
        "            self.shortcut = nn.Sequential(\r\n",
        "                nn.Conv2d(in_planes, out_planes, kernel_size=1, \r\n",
        "                          stride=1, padding=0, bias=False),\r\n",
        "                nn.BatchNorm2d(out_planes),\r\n",
        "            )\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\r\n",
        "        out = self.bn3(self.conv3(out))\r\n",
        "        out = out + self.shortcut(x) if self.stride==1 else out\r\n",
        "        return out\r\n",
        "\r\n",
        "\r\n",
        "class MobileNetV2(nn.Module):\r\n",
        "    # (expansion, out_planes, num_blocks, stride)\r\n",
        "    cfg = [(1,  16, 1, 1),\r\n",
        "           (6,  24, 2, 1),  # NOTE: change stride 2 -> 1 for CIFAR10\r\n",
        "           (6,  32, 3, 2),\r\n",
        "           (6,  64, 4, 2),\r\n",
        "           (6,  96, 3, 1),\r\n",
        "           (6, 160, 3, 2),\r\n",
        "           (6, 320, 1, 1)]\r\n",
        "\r\n",
        "    def __init__(self, num_classes=10):\r\n",
        "        super(MobileNetV2, self).__init__()\r\n",
        "        # NOTE: change conv1 stride 2 -> 1 for CIFAR10\r\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, \r\n",
        "                               padding=1, bias=False)\r\n",
        "        self.bn1 = nn.BatchNorm2d(32)\r\n",
        "        self.layers = self._make_layers(in_planes=32)\r\n",
        "        self.conv2 = nn.Conv2d(320, 1280, kernel_size=1, stride=1, \r\n",
        "                               padding=0, bias=False)\r\n",
        "        self.bn2 = nn.BatchNorm2d(1280)\r\n",
        "        self.linear = nn.Linear(1280, num_classes)\r\n",
        "\r\n",
        "    def _make_layers(self, in_planes):\r\n",
        "        layers = []\r\n",
        "        for expansion, out_planes, num_blocks, stride in self.cfg:\r\n",
        "            strides = [stride] + [1]*(num_blocks-1)\r\n",
        "            for stride in strides:\r\n",
        "                layers.append(\r\n",
        "                    Block(in_planes, out_planes, expansion, stride))\r\n",
        "                in_planes = out_planes\r\n",
        "        return nn.Sequential(*layers)\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\r\n",
        "        out = self.layers(out)\r\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\r\n",
        "        # NOTE: change pooling kernel_size 7 -> 4 for CIFAR10\r\n",
        "        out = F.avg_pool2d(out, 4)\r\n",
        "        out = out.view(out.size(0), -1)\r\n",
        "        out = self.linear(out)\r\n",
        "        return out\r\n",
        "    def train_sgd(self,device):\r\n",
        "        optimizer = optim.Adam(self.parameters(), lr=0.0001)\r\n",
        "\r\n",
        "        path = 'weights.tar'\r\n",
        "        initepoch = 0\r\n",
        "\r\n",
        "        if os.path.exists(path) is not True:\r\n",
        "            loss = nn.CrossEntropyLoss()\r\n",
        "            # optimizer = optim.SGD(self.parameters(),lr=0.01)\r\n",
        "\r\n",
        "        else:\r\n",
        "            checkpoint = torch.load(path)\r\n",
        "            self.load_state_dict(checkpoint['model_state_dict'])\r\n",
        "            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\r\n",
        "            initepoch = checkpoint['epoch']\r\n",
        "            loss = checkpoint['loss']\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "        for epoch in range(initepoch,100):  # loop over the dataset multiple times\r\n",
        "            timestart = time.time()\r\n",
        "\r\n",
        "            running_loss = 0.0\r\n",
        "            total = 0\r\n",
        "            correct = 0\r\n",
        "            for i, data in enumerate(trainloader, 0):\r\n",
        "                # get the inputs\r\n",
        "                inputs, labels = data\r\n",
        "                inputs, labels = inputs.to(device),labels.to(device)\r\n",
        "\r\n",
        "                # zero the parameter gradients\r\n",
        "                optimizer.zero_grad()\r\n",
        "\r\n",
        "                # forward + backward + optimize\r\n",
        "                outputs = self(inputs)\r\n",
        "                l = loss(outputs, labels)\r\n",
        "                l.backward()\r\n",
        "                optimizer.step()\r\n",
        "\r\n",
        "                # print statistics\r\n",
        "                running_loss += l.item()\r\n",
        "                # print(\"i \",i)\r\n",
        "                if i % 500 == 499:  # print every 500 mini-batches\r\n",
        "                    print('[%d, %5d] loss: %.4f' %\r\n",
        "                          (epoch, i, running_loss / 500))\r\n",
        "                    running_loss = 0.0\r\n",
        "                    _, predicted = torch.max(outputs.data, 1)\r\n",
        "                    total += labels.size(0)\r\n",
        "                    correct += (predicted == labels).sum().item()\r\n",
        "                    print('Accuracy of the network on the %d tran images: %.3f %%' % (total,\r\n",
        "                            100.0 * correct / total))\r\n",
        "                    total = 0\r\n",
        "                    correct = 0\r\n",
        "                    torch.save({'epoch':epoch,\r\n",
        "                                'model_state_dict':net.state_dict(),\r\n",
        "                                'optimizer_state_dict':optimizer.state_dict(),\r\n",
        "                                'loss':loss\r\n",
        "                                },path)\r\n",
        "\r\n",
        "            print('epoch %d cost %3f sec' %(epoch,time.time()-timestart))\r\n",
        "\r\n",
        "        print('Finished Training')\r\n",
        "    def test(self,device):\r\n",
        "        correct = 0\r\n",
        "        total = 0\r\n",
        "        with torch.no_grad():\r\n",
        "            for data in testloader:\r\n",
        "                images, labels = data\r\n",
        "                images, labels = images.to(device), labels.to(device)\r\n",
        "                outputs = self(images)\r\n",
        "                _, predicted = torch.max(outputs.data, 1)\r\n",
        "                total += labels.size(0)\r\n",
        "                correct += (predicted == labels).sum().item()\r\n",
        "\r\n",
        "        print('Accuracy of the network on the 10000 test images: %.3f %%' % (\r\n",
        "                100.0 * correct / total))\r\n",
        "inputs, labels = data\r\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "inputs, labels = inputs.to(device),labels.to(device)\r\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VVsp6N_XPRBY",
        "outputId": "2c5ad067-5f38-444b-dcb1-c1ae60125a61"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\r\n",
        "net = MobileNetV2()\r\n",
        "net = net.to(device)\r\n",
        "net.train_sgd(device)\r\n",
        "net.test(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0,   499] loss: 1.7205\n",
            "Accuracy of the network on the 100 tran images: 45.000 %\n",
            "epoch 0 cost 2534.015327 sec\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "grTdc7PfTPsB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}